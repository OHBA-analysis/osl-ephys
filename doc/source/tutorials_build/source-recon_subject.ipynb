{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Single Subject Source Reconstruction Tutorial\n\nIn this tutorial, we will step through how to do source reconstruction (and parcellation) on a single session of data from a subject in the Wakeman-Henson task MEG dataset. This is a public dataset consisting of 19 healthy individuals who performed a simple visual perception task. See [Wakeman & Henson](https://www.nature.com/articles/sdata20151) for more details.\n \nThe steps we will follow are:\n \n1. Downloading the data from OSF\n2. Setup file names\n3. Compute surfaces, perform coregistration, and compute forward model using batching\n4. Temporal Filtering\n5. Compute beamformer weights\n6. Apply beamformer weights\n7. Parcellation\n8. Epoching\n\nNote that most of these steps can be carried out more simply over multiple subjects using batching. See the \"Group Analysis of Source-space Data\" tutorial for an example of this. Here we break the steps down and run them manually, to give you insight into how it all works.\n\nTo run this tutorial you will need to have osl-ephys and FSL installed, with the appropriate paths specified in your environment. See the instructions on the repo/read the docs for how to install these packages.\n\n\n## 1. Downloading the raw data from OSF\n\nThe public Wakeman-Henson dataset provides MaxFiltered data. Note that the full dataset is available on [OpenNeuro](https://openneuro.org/datasets/ds000117/versions/1.0.4). Here, we will work with just a single subject from this dataset, which can be downloaded from the OSF project website. \n\nLet's download the data. Note, to download the dataset you need ``osfclient`` installed. This can be installed by excuting the following code in a jupyter notebook cell:\n\n``!pip install osfclient``\n\nWe can now download the data for the single subject we will look at. Note that this will be placed in your current working directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\ndef get_data(name):\n    print('Data will be in directory {}'.format(os.getcwd()))\n    \"\"\"Download a dataset from OSF.\"\"\"\n    if os.path.exists(f\"{name}\"):\n        return f\"{name} already downloaded. Skipping..\"\n    os.system(f\"osf -p zxb6c fetch SourceRecon/data/{name}.zip\")\n    os.system(f\"unzip -o {name}.zip\")\n    os.remove(f\"{name}.zip\")\n    return f\"Data downloaded to: {name}\"\n\n# Download the dataset\nget_data(\"wake_hen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup File Names\nLet's first setup all the file names we will need, for an example single session from a single subject from the Wakeman-Henson dataset. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nfrom pprint import pprint\nfrom osl_ephys import utils\n\n# setup dirs\ndata_dir = './wake_hen'\nrecon_dir = op.join(data_dir, \"recon\")\nout_dir = op.join(data_dir, \"recon\", \"glm\")\n\n# structurals\nsub_name = \"sub{sub_num}\"\nsmri_files_path = op.join(data_dir, sub_name, \"anatomy\", \"highres001.nii.gz\")\nsmri_files = utils.Study(smri_files_path).get()\n\n# fif files\nsubject = \"{subject}\"\npreproc_fif_files_path = op.join(data_dir, subject + \"_meg\", subject + \"_meg_preproc_raw.fif\")\npreproc_fif_files = utils.Study(preproc_fif_files_path)\nsubjects = preproc_fif_files.fields['subject']\npreproc_fif_files = preproc_fif_files.get()\n\n# setup output file names\nsflip_parc_files=[]\nfor subject in subjects:\n    sflip_parc_files.append(op.join(recon_dir, subject, \"sflip_parc.npy\"))\n\nprint('subjects:')\npprint(subjects)\n\nprint('Structural files:')\npprint(smri_files)\n\nprint('Preproc fif files:')\npprint(preproc_fif_files)\n\nprint('Sign flipped parcellated files:')\npprint(sflip_parc_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Compute Surfaces, Coregistration and Forward Modelling\n\nHere, we set the options in the dictionary ``config``, and use ``source_recon.run_src_batch``.\nSee the tutorial on \"Coregistration with RHINO\" for more on how this works.\n\nWe do not use the nose and headshape points as these were not acquired for this dataset.\n\nSetting ``gridstep: 10`` means that the data will be source reconstructed to each point on a regular 3D grid, with spacings of 10mm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from osl_ephys import source_recon\n\nconfig = \"\"\"\n    source_recon:\n    - extract_fiducials_from_fif: {}\n    - compute_surfaces:\n        include_nose: false\n    - coregister:\n        use_nose: false\n        use_headshape: false\n    - forward_model:\n        model: Single Layer\n        gridstep: 10\n\"\"\"\nfsl_dir = '~/fsl'\nsource_recon.setup_fsl(fsl_dir)\n\nsource_recon.run_src_batch(\n    config,\n    src_dir=recon_dir,\n    subjects=subjects,\n    preproc_files=preproc_fif_files,\n    smri_files=smri_files,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Temporal Filtering\n\nWe temporally filter the data to focus on the oscillatory content that we are interest in. \n\nHere, we assume that we will be doing an evoked response (ERF) analysis on the epoched task data, and so we filter to the frequency range where the evoked response is typically contained, i.e. between 1 and 30 Hz.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne\n\nchantypes = [\"grad\"]\n\n# Get and setup the data\ndata = mne.io.read_raw_fif(preproc_fif_files[0], preload=True)\ndata = data.pick(chantypes)\n\n# Filter to the beta band\nprint(\"Temporal Filtering\")\ndata = data.filter(\n    l_freq=3,\n    h_freq=20,\n    method=\"iir\",\n    iir_params={\"order\": 5, \"btype\": \"bandpass\", \"ftype\": \"butter\"},\n)\nprint(\"Completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compute beamformer weights\n\nWe now compute the beamformer weights (aka filters). These are computed using the (sensors x sensors) data covariance matrix estimated from the preprocessed and the temporally filtered MEG data (contained in *raw*), and the forward models (contained inside the ``subjects[0]`` inside the directory ``recon_dir``. \n\nNote that this automatically ignores any bad time segments when calculating the beamformer filters.\n\nHere we source reconstructing using just the gradiometers.\n\nThe MEG data in the Wakeman and Henson dataset has been maxfiltered and so the maximum rank is ~64. We therefore slightly conservatively set the rank to be 55. This is used to regularise the estimate of the data covariance matrix.\n\nMore generally, a dipole is a 3D vector in space. Setting ``pick_ori=\"max-power-pre-weight-norm\"`` means that we are computing a scalar beamformer, by projecting this 3D vector on the direction in which there is maximum power. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from osl_ephys.source_recon import rhino, beamforming, parcellation\n      \n# Make LCMV beamformer filters\n# Note that this will exclude any bad time segments when calculating the beamformer filters\nfilters = beamforming.make_lcmv(\n    recon_dir,\n    subjects[0],\n    data,\n    chantypes,\n    pick_ori=\"max-power-pre-weight-norm\",\n    rank={\"grad\": 55},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Applying beamformer weights\n\nWe now apply the beamformer filters to the data to project the data into source space.\n\nNote that although the beamformer filters were calculated by ignoring any bad time segments, we apply the filters to all time points including the bad time segments. This will make it easier to do epoching later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Applying beamformer spatial filters\")\n\n# stc is source space time series (in head/polhemus space).\nstc = beamforming.apply_lcmv(data, filters)\n\n# Convert from head/polhemus space to standard brain grid in MNI space\nrecon_timeseries_mni, reference_brain_fname, recon_coords_mni, _ = \\\n        beamforming.transform_recon_timeseries(recon_dir, \n                                                subjects[0], \n                                                recon_timeseries=stc.data, \n                                                reference_brain=\"mni\")\n\nprint(\"Completed\")\nprint(\"Dimensions of reconstructed timeseries in MNI space is (dipoles x all_tpts) = {}\".format(recon_timeseries_mni.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Parcellation\n\nAt this point, the data has been source reconstructed to dipoles (in this case, a scalar value) at each point on a regular 3D grid, with spacings of 10mm. We could then analyse the data across all these dipoles.\n\nAn alternative, is to map the data onto a brain parcellation. This reduces the number of samples in the space from number of dipoles down to number of parcels. Using a parcellation helps to boost the signal to noise ratio, boost correspondance between subjects, reduce the severity of multiple comparison correction when doing any statistics, and aids anatomical interpretability.\n\nThe parcellation we use here is a combination of cortical regions from the Harvard Oxford atlas, and selected sub-cortical regions from the Schaefer 100 parcellation. \n\nLet's take a look at the positions of the centres of each parcel in the parcellation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parcellation_fname = 'HarvOxf-sub-Schaefer100-combined-2mm_4d_ds8.nii.gz'\n\n# plot centre of mass for each parcel\np = parcellation.plot_parcellation(parcellation_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute Parcel Time-courses\n\nWe use this parcellation to compute the parcel time courses using the parcellation and the dipole time courses. Note that the output parcel timepoints includes all time points, including any bad time segments.\n\nLet's now parcellate the data to compute parcel time courses. This is done using the \"spatial_basis\" method, where the parcel time-course \nfirst principal component from all voxels, weighted by the spatial map for the parcel (see [here](https://pubmed.ncbi.nlm.nih.gov/25862259/)).\n\n\nApply parcellation to (voxels x all_tpts) data contained in recon_timeseries_mni.\nThe resulting parcel_timeseries will be (parcels x all_tpts) in MNI space\nwhere all_tpts includes bad time segments\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parcel_ts, _, _ = parcellation.parcellate_timeseries(\n    parcellation_fname, \n    recon_timeseries_mni, \n    recon_coords_mni, \n    \"spatial_basis\", \n    recon_dir,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now put the parcel time courses into a new MNE raw object *parc_raw*. This will allow us to easily perform epoching using MNE.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# reload raw data to ensure that the stim channel is in there\nraw = mne.io.read_raw_fif(preproc_fif_files[0])\n\nparc_raw = parcellation.convert2mne_raw(parcel_ts, raw)\n\nprint(\"Dimensions of parc_raw are (nparcels x all_tpts) = {}\".format(parc_raw.get_data().shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Epoching\n\nWe can now perform epoching. Note that any epochs (aka trials) that contain any bad time segments will be rejected at this point.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from osl_ephys import preprocessing\n\ndataset = preprocessing.read_dataset(preproc_fif_files[0])\nepochs = mne.Epochs(\n    parc_raw,\n    dataset[\"events\"],\n    dataset[\"event_id\"],\n    tmin=-1,\n    tmax=3,\n    baseline=(None, 0),\n)\n\nprint(\"Dimensions of epochs are (good_epochs x parcels x tpts_within_epoch) = {}\".format(epochs.get_data().shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now plot a simple evoked response for this session of data, by averaging over all epochs (aka trials), for a selected parcel\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\nparcel_ind = 5\nprint(\"Plotting group COPE time course for parcel:\", parcel_ind)\n\n# average over trials/epochs\nerf = np.mean(epochs.get_data()[:, parcel_ind, :], axis=0)\n\nplt.figure()\nplt.plot(epochs.times, erf)\nplt.title(\"ERF, for parcel={}\".format(parcel_ind))\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"ERF\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}